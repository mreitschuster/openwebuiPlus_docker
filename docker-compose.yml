services:
  openWebUI:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: always
    ports:
      - "3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./open-webui-local:/app/backend/data
      - ./docs:/app/backend/data/docs
    environment:
    # see https://docs.openwebui.com/getting-started/env-configuration#speech-to-text
      - ENABLE_OPENAI_API=true
      - OPENAI_API_BASE_URL=http://pipelines:9099
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URL=http://ollama:11434 #http://host.docker.internal:11434
      - WEBUI_AUTH=false
      - AUTOMATIC1111_BASE_URL=http://automatic1111:7860
      - ENABLE_IMAGE_GENERATION=True
      #- RAG_EMBEDDING_ENGINE=ollama
      #- AUDIO_STT_ENGINE=openai
      #- AUDIO_TTS_ENGINE=openai
      - AUDIO_TTS_OPENAI_API_BASE_URL=http://host.docker.internal:8000/v1 #http://openedai-speech:8000 #http://host.docker.internal:8000/v1
      - AUDIO_TTS_OPENAI_API_KEY="sk-111111111"
      #- AUDIO_TTS_MODEL="tts-1-hd"
      #- AUDIO_TTS_VOICE="alloy"
      - ENABLE_IMAGE_GENERATION=True
      - IMAGE_GENERATION_ENGINE=automatic1111
      - AUTOMATIC1111_BASE_URL=http://automatic1111:7860
      #- IMAGE_STEPS=50
      #- IMAGE_GENERATION_MODEL="v1-5-pruned-emaonly.safetensors"

  ollama:
    image: ollama/ollama:latest  
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama-local:/root/.ollama
      #- ./docs:/data/docs
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]


  automatic1111:
    build: ./build/automatic1111
    container_name: automatic1111
    restart: always
    ports:
      - "7860:7860"
    volumes:
      - ./stable-diffusion-webui/models:/stable-diffusion-webui/models
      - ./stable-diffusion-webui/repositories:/stable-diffusion-webui/repositories
      #- ./stable-diffusion-webui/venv:/stable-diffusion-webui/venv

    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment:
      - CUDA_VISIBLE_DEVICES=0

  openedai-speech:
    image: ghcr.io/matatonic/openedai-speech
    container_name: openedai-speech
    
    ports:
      - "8000:8000"
    volumes:
      - ./tts-voices:/app/voices
      - ./tts-config:/app/config
    environment:
      - TTS_HOME=voices
      - HF_HOME=voices
    # labels:
    #   - "com.centurylinklabs.watchtower.enable=true"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    ports:
      - "9099:9099"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./pipelines:/app/pipelines
    restart: always
