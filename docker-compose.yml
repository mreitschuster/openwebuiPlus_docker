services:
  openWebUI:
    image: ghcr.io/open-webui/open-webui:main
    restart: always
    ports:
      - "3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./open-webui-local:/app/backend/data
      - ./docs:/data/docs
    environment:
      - WEBUI_AUTH=false
      - AUTOMATIC1111_BASE_URL=http://automatic1111:7860
      - ENABLE_IMAGE_GENERATION=True


  ollama:
    image: ollama/ollama:latest  #:0.1.34
    ports:
      - "11434:11434"
    volumes:
      - ./ollama-local:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]


  automatic1111:
    build: ./build/automatic1111
    restart: always
    ports:
      - "7860:7860"
    volumes:
      - ./stable-diffusion-webui:/stable-diffusion-webui
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment:
      - CUDA_VISIBLE_DEVICES=0



